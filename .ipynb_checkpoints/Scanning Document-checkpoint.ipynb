{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "import cv2\n",
    "from pylsd.lsd import lsd\n",
    "\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Scanning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocScanner(object):\n",
    "    \"\"\"An image scanner\"\"\"\n",
    "\n",
    "    def __init__(self, interactive=False, MIN_QUAD_AREA_RATIO=0.25, MAX_QUAD_ANGLE_RANGE=40):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            interactive (boolean): If True, user can adjust screen contour before\n",
    "                transformation occurs in interactive pyplot window.\n",
    "            MIN_QUAD_AREA_RATIO (float): A contour will be rejected if its corners \n",
    "                do not form a quadrilateral that covers at least MIN_QUAD_AREA_RATIO \n",
    "                of the original image. Defaults to 0.25.\n",
    "            MAX_QUAD_ANGLE_RANGE (int):  A contour will also be rejected if the range \n",
    "                of its interior angles exceeds MAX_QUAD_ANGLE_RANGE. Defaults to 40.\n",
    "        \"\"\"        \n",
    "        self.interactive = interactive\n",
    "        self.MIN_QUAD_AREA_RATIO = MIN_QUAD_AREA_RATIO\n",
    "        self.MAX_QUAD_ANGLE_RANGE = MAX_QUAD_ANGLE_RANGE        \n",
    "\n",
    "    def filter_corners(self, corners, min_dist=20):\n",
    "        \"\"\"Filters corners that are within min_dist of others\"\"\"\n",
    "        def predicate(representatives, corner):\n",
    "            return all(dist.euclidean(representative, corner) >= min_dist\n",
    "                       for representative in representatives)\n",
    "\n",
    "        filtered_corners = []\n",
    "        for c in corners:\n",
    "            if predicate(filtered_corners, c):\n",
    "                filtered_corners.append(c)\n",
    "        return filtered_corners\n",
    "\n",
    "    def angle_between_vectors_degrees(self, u, v):\n",
    "        \"\"\"Returns the angle between two vectors in degrees\"\"\"\n",
    "        return np.degrees(\n",
    "            math.acos(np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))))\n",
    "\n",
    "    def get_angle(self, p1, p2, p3):\n",
    "        \"\"\"\n",
    "        Returns the angle between the line segment from p2 to p1 \n",
    "        and the line segment from p2 to p3 in degrees\n",
    "        \"\"\"\n",
    "        a = np.radians(np.array(p1))\n",
    "        b = np.radians(np.array(p2))\n",
    "        c = np.radians(np.array(p3))\n",
    "\n",
    "        avec = a - b\n",
    "        cvec = c - b\n",
    "\n",
    "        return self.angle_between_vectors_degrees(avec, cvec)\n",
    "\n",
    "    def angle_range(self, quad):\n",
    "        \"\"\"\n",
    "        Returns the range between max and min interior angles of quadrilateral.\n",
    "        The input quadrilateral must be a numpy array with vertices ordered clockwise\n",
    "        starting with the top left vertex.\n",
    "        \"\"\"\n",
    "        tl, tr, br, bl = quad\n",
    "        ura = self.get_angle(tl[0], tr[0], br[0])\n",
    "        ula = self.get_angle(bl[0], tl[0], tr[0])\n",
    "        lra = self.get_angle(tr[0], br[0], bl[0])\n",
    "        lla = self.get_angle(br[0], bl[0], tl[0])\n",
    "\n",
    "        angles = [ura, ula, lra, lla]\n",
    "        return np.ptp(angles)          \n",
    "\n",
    "    def get_corners(self, img):\n",
    "        \"\"\"\n",
    "        Returns a list of corners ((x, y) tuples) found in the input image. With proper\n",
    "        pre-processing and filtering, it should output at most 10 potential corners.\n",
    "        This is a utility function used by get_contours. The input image is expected \n",
    "        to be rescaled and Canny filtered prior to be passed in.\n",
    "        \"\"\"\n",
    "        lines = lsd(img)\n",
    "\n",
    "        # massages the output from LSD\n",
    "        # LSD operates on edges. One \"line\" has 2 edges, and so we need to combine the edges back into lines\n",
    "        # 1. separate out the lines into horizontal and vertical lines.\n",
    "        # 2. Draw the horizontal lines back onto a canvas, but slightly thicker and longer.\n",
    "        # 3. Run connected-components on the new canvas\n",
    "        # 4. Get the bounding box for each component, and the bounding box is final line.\n",
    "        # 5. The ends of each line is a corner\n",
    "        # 6. Repeat for vertical lines\n",
    "        # 7. Draw all the final lines onto another canvas. Where the lines overlap are also corners\n",
    "\n",
    "        corners = []\n",
    "        if lines is not None:\n",
    "            # separate out the horizontal and vertical lines, and draw them back onto separate canvases\n",
    "            lines = lines.squeeze().astype(np.int32).tolist()\n",
    "            horizontal_lines_canvas = np.zeros(img.shape, dtype=np.uint8)\n",
    "            vertical_lines_canvas = np.zeros(img.shape, dtype=np.uint8)\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2, _ = line\n",
    "                if abs(x2 - x1) > abs(y2 - y1):\n",
    "                    (x1, y1), (x2, y2) = sorted(((x1, y1), (x2, y2)), key=lambda pt: pt[0])\n",
    "                    cv2.line(horizontal_lines_canvas, (max(x1 - 5, 0), y1), (min(x2 + 5, img.shape[1] - 1), y2), 255, 2)\n",
    "                else:\n",
    "                    (x1, y1), (x2, y2) = sorted(((x1, y1), (x2, y2)), key=lambda pt: pt[1])\n",
    "                    cv2.line(vertical_lines_canvas, (x1, max(y1 - 5, 0)), (x2, min(y2 + 5, img.shape[0] - 1)), 255, 2)\n",
    "\n",
    "            lines = []\n",
    "\n",
    "            # find the horizontal lines (connected-components -> bounding boxes -> final lines)\n",
    "            (contours, hierarchy) = cv2.findContours(horizontal_lines_canvas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contours = sorted(contours, key=lambda c: cv2.arcLength(c, True), reverse=True)[:2]\n",
    "            horizontal_lines_canvas = np.zeros(img.shape, dtype=np.uint8)\n",
    "            for contour in contours:\n",
    "                contour = contour.reshape((contour.shape[0], contour.shape[2]))\n",
    "                min_x = np.amin(contour[:, 0], axis=0) + 2\n",
    "                max_x = np.amax(contour[:, 0], axis=0) - 2\n",
    "                left_y = int(np.average(contour[contour[:, 0] == min_x][:, 1]))\n",
    "                right_y = int(np.average(contour[contour[:, 0] == max_x][:, 1]))\n",
    "                lines.append((min_x, left_y, max_x, right_y))\n",
    "                cv2.line(horizontal_lines_canvas, (min_x, left_y), (max_x, right_y), 1, 1)\n",
    "                corners.append((min_x, left_y))\n",
    "                corners.append((max_x, right_y))\n",
    "\n",
    "            # find the vertical lines (connected-components -> bounding boxes -> final lines)\n",
    "            (contours, hierarchy) = cv2.findContours(vertical_lines_canvas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contours = sorted(contours, key=lambda c: cv2.arcLength(c, True), reverse=True)[:2]\n",
    "            vertical_lines_canvas = np.zeros(img.shape, dtype=np.uint8)\n",
    "            for contour in contours:\n",
    "                contour = contour.reshape((contour.shape[0], contour.shape[2]))\n",
    "                min_y = np.amin(contour[:, 1], axis=0) + 2\n",
    "                max_y = np.amax(contour[:, 1], axis=0) - 2\n",
    "                top_x = int(np.average(contour[contour[:, 1] == min_y][:, 0]))\n",
    "                bottom_x = int(np.average(contour[contour[:, 1] == max_y][:, 0]))\n",
    "                lines.append((top_x, min_y, bottom_x, max_y))\n",
    "                cv2.line(vertical_lines_canvas, (top_x, min_y), (bottom_x, max_y), 1, 1)\n",
    "                corners.append((top_x, min_y))\n",
    "                corners.append((bottom_x, max_y))\n",
    "\n",
    "            # find the corners\n",
    "            corners_y, corners_x = np.where(horizontal_lines_canvas + vertical_lines_canvas == 2)\n",
    "            corners += zip(corners_x, corners_y)\n",
    "\n",
    "        # remove corners in close proximity\n",
    "        corners = self.filter_corners(corners)\n",
    "        return corners\n",
    "\n",
    "    def is_valid_contour(self, cnt, IM_WIDTH, IM_HEIGHT):\n",
    "        \"\"\"Returns True if the contour satisfies all requirements set at instantitation\"\"\"\n",
    "\n",
    "        return (len(cnt) == 4 and cv2.contourArea(cnt) > IM_WIDTH * IM_HEIGHT * self.MIN_QUAD_AREA_RATIO \n",
    "            and self.angle_range(cnt) < self.MAX_QUAD_ANGLE_RANGE)\n",
    "\n",
    "    '''-------------------------'''\n",
    "    def order_points(self, pts):\n",
    "        # sort the points based on their x-coordinates\n",
    "        xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "        # grab the left-most and right-most points from the sorted\n",
    "        # x-roodinate points\n",
    "        leftMost = xSorted[:2, :]\n",
    "        rightMost = xSorted[2:, :]\n",
    "        # now, sort the left-most coordinates according to their\n",
    "        # y-coordinates so we can grab the top-left and bottom-left\n",
    "        # points, respectively\n",
    "        leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "        (tl, bl) = leftMost\n",
    "        # now that we have the top-left coordinate, use it as an\n",
    "        # anchor to calculate the Euclidean distance between the\n",
    "        # top-left and right-most points; by the Pythagorean\n",
    "        # theorem, the point with the largest distance will be\n",
    "        # our bottom-right point\n",
    "        D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "        (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "        # return the coordinates in top-left, top-right,\n",
    "        # bottom-right, and bottom-left order\n",
    "        return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "    '''-------------------------'''\n",
    "    \n",
    "    \n",
    "    def get_contour(self, rescaled_image):\n",
    "        \"\"\"\n",
    "        Returns a numpy array of shape (4, 2) containing the vertices of the four corners\n",
    "        of the document in the image. It considers the corners returned from get_corners()\n",
    "        and uses heuristics to choose the four corners that most likely represent\n",
    "        the corners of the document. If no corners were found, or the four corners represent\n",
    "        a quadrilateral that is too small or convex, it returns the original four corners.\n",
    "        \"\"\"\n",
    "\n",
    "        # these constants are carefully chosen\n",
    "        MORPH = 9\n",
    "        CANNY = 84\n",
    "        HOUGH = 25\n",
    "\n",
    "        IM_HEIGHT, IM_WIDTH, _ = rescaled_image.shape\n",
    "\n",
    "        # convert the image to grayscale and blur it slightly\n",
    "        gray = cv2.cvtColor(rescaled_image, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "\n",
    "        # dilate helps to remove potential holes between edge segments\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(MORPH,MORPH))\n",
    "        dilated = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # find edges and mark them in the output map using the Canny algorithm\n",
    "        edged = cv2.Canny(dilated, 0, CANNY)\n",
    "        test_corners = self.get_corners(edged)\n",
    "\n",
    "        approx_contours = []\n",
    "\n",
    "        if len(test_corners) >= 4:\n",
    "            quads = []\n",
    "\n",
    "            for quad in itertools.combinations(test_corners, 4):\n",
    "                points = np.array(quad)\n",
    "                points = self.order_points(points)\n",
    "                points = np.array([[p] for p in points], dtype = \"int32\")\n",
    "                quads.append(points)\n",
    "\n",
    "            # get top five quadrilaterals by area\n",
    "            quads = sorted(quads, key=cv2.contourArea, reverse=True)[:5]\n",
    "            # sort candidate quadrilaterals by their angle range, which helps remove outliers\n",
    "            quads = sorted(quads, key=self.angle_range)\n",
    "\n",
    "            approx = quads[0]\n",
    "            if self.is_valid_contour(approx, IM_WIDTH, IM_HEIGHT):\n",
    "                approx_contours.append(approx)\n",
    "\n",
    "            # for debugging: uncomment the code below to draw the corners and countour found \n",
    "            # by get_corners() and overlay it on the image\n",
    "\n",
    "#             cv2.drawContours(rescaled_image, [approx], -1, (20, 20, 255), 2)\n",
    "#             plt.scatter(*zip(*test_corners))\n",
    "#             cv2.imshow('contours', rescaled_image)\n",
    "#             plt.show()\n",
    "\n",
    "        # also attempt to find contours directly from the edged image, which occasionally \n",
    "        # produces better results\n",
    "        (cnts, hierarchy) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "        # loop over the contours\n",
    "        for c in cnts:\n",
    "            # approximate the contour\n",
    "            approx = cv2.approxPolyDP(c, 80, True)\n",
    "            if self.is_valid_contour(approx, IM_WIDTH, IM_HEIGHT):\n",
    "                approx_contours.append(approx)\n",
    "                break\n",
    "\n",
    "        # If we did not find any valid contours, just use the whole image\n",
    "        if not approx_contours:\n",
    "            TOP_RIGHT = (IM_WIDTH, 0)\n",
    "            BOTTOM_RIGHT = (IM_WIDTH, IM_HEIGHT)\n",
    "            BOTTOM_LEFT = (0, IM_HEIGHT)\n",
    "            TOP_LEFT = (0, 0)\n",
    "            screenCnt = np.array([[TOP_RIGHT], [BOTTOM_RIGHT], [BOTTOM_LEFT], [TOP_LEFT]])\n",
    "\n",
    "        else:\n",
    "            screenCnt = max(approx_contours, key=cv2.contourArea)\n",
    "            \n",
    "        return screenCnt.reshape(4, 2)\n",
    "    \n",
    "    \n",
    "    '''-------------------------'''\n",
    "    def four_point_transform(self, image, pts):\n",
    "        # obtain a consistent order of the points and unpack them\n",
    "        # individually\n",
    "        rect = self.order_points(pts)\n",
    "        (tl, tr, br, bl) = rect\n",
    "        # compute the width of the new image, which will be the\n",
    "        # maximum distance between bottom-right and bottom-left\n",
    "        # x-coordiates or the top-right and top-left x-coordinates\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "        # compute the height of the new image, which will be the\n",
    "        # maximum distance between the top-right and bottom-right\n",
    "        # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "        # now that we have the dimensions of the new image, construct\n",
    "        # the set of destination points to obtain a \"birds eye view\",\n",
    "        # (i.e. top-down view) of the image, again specifying points\n",
    "        # in the top-left, top-right, bottom-right, and bottom-left\n",
    "        # order\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [maxWidth - 1, 0],\n",
    "            [maxWidth - 1, maxHeight - 1],\n",
    "            [0, maxHeight - 1]], dtype = \"float32\")\n",
    "        # compute the perspective transform matrix and then apply it\n",
    "        M = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "        # return the warped image\n",
    "        return warped\n",
    "    '''-------------------------'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Images Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale, imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Running Of The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n",
      "(675, 1200, 3)\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "widthImg = 1200\n",
    "heightImg = 675\n",
    "###################################\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(10,150)\n",
    "docCap = DocScanner()\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img, (widthImg, heightImg))\n",
    "#     print(img.shape)\n",
    "                     \n",
    "    # get the contour of the document\n",
    "    screenCnt = docCap.get_contour(img)\n",
    "\n",
    "    # apply the perspective transformation\n",
    "    warped = docCap.four_point_transform(img, screenCnt)\n",
    "\n",
    "    # convert the warped image to grayscale\n",
    "    gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # sharpen image\n",
    "    sharpen1 = cv2.GaussianBlur(gray, (0,0), 3)\n",
    "    sharpen2 = cv2.addWeighted(gray, 1.5, sharpen1, -0.5, 0)\n",
    "\n",
    "    # apply adaptive threshold to get black and white effect\n",
    "    thresh = cv2.adaptiveThreshold(sharpen2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 15)\n",
    "    \n",
    "    imageArray = ([img, sharpen1],\n",
    "                  [sharpen2, thresh])\n",
    "\n",
    "    stackedImages = stackImages(0.6, imageArray)\n",
    "    cv2.imshow(\"WorkFlow\", stackedImages)\n",
    "                     \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "# reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[296, 214], [322, 214], [322, 238], [296, 238]], '', 0.3925476372241974),\n",
       " ([[363, 249], [413, 249], [413, 285], [363, 285]], 'yo', 0.21237953007221222),\n",
       " ([[363, 197], [449, 197], [449, 287], [363, 287]], '3#', 0.3568163216114044),\n",
       " ([[498, 196], [614, 196], [614, 294], [498, 294]],\n",
       "  'ispy',\n",
       "  0.10311081260442734),\n",
       " ([[510, 254], [558, 254], [558, 286], [510, 286]], 'Lo', 0.23831135034561157),\n",
       " ([[381, 293], [421, 293], [421, 333], [381, 333]], '5', 0.95884108543396),\n",
       " ([[302, 374], [338, 374], [338, 402], [302, 402]], 's', 0.15439863502979279),\n",
       " ([[354, 366], [442, 366], [442, 416], [354, 416]],\n",
       "  '+24',\n",
       "  0.22040800750255585),\n",
       " ([[457, 377], [483, 377], [483, 397], [457, 397]], '', 0.5850533246994019),\n",
       " ([[475, 359], [565, 359], [565, 421], [475, 421]],\n",
       "  'Is94',\n",
       "  0.4253748655319214),\n",
       " ([[366, 410], [432, 410], [432, 464], [366, 464]], 'to9', 0.3372949957847595),\n",
       " ([[287, 491], [413, 491], [413, 533], [287, 533]],\n",
       "  'lox +',\n",
       "  0.14567328989505768),\n",
       " ([[503, 511], [527, 511], [527, 531], [503, 531]], '', 0.5376031994819641),\n",
       " ([[247, 557], [502, 557], [502, 674], [247, 674]],\n",
       "  'Ss+&y',\n",
       "  0.14395944774150848),\n",
       " ([[572, 594], [646, 594], [646, 650], [572, 650]], '3v', 0.18684899806976318),\n",
       " ([[433, 661], [512, 661], [512, 704], [433, 704]],\n",
       "  '9 5',\n",
       "  0.20636777579784393),\n",
       " ([[313, 733], [471, 733], [471, 793], [313, 793]],\n",
       "  'Ioc=',\n",
       "  0.2923274636268616),\n",
       " ([[496, 726], [610, 726], [610, 846], [496, 846]], '3g', 0.3858753740787506),\n",
       " ([[321, 857], [403, 857], [403, 901], [321, 901]], 'fo', 0.23510834574699402),\n",
       " ([[502, 842], [604, 842], [604, 918], [502, 918]], \"'3y\", 0.1824190616607666),\n",
       " ([[525, 911], [575, 911], [575, 947], [525, 947]], 'Te', 0.3123721480369568),\n",
       " ([[426.0984799331589, 483.0582954853233],\n",
       "   [505.78203950138555, 515.2668121274237],\n",
       "   [480.9015200668411, 573.9417045146766],\n",
       "   [402.21796049861445, 541.7331878725763]],\n",
       "  '29',\n",
       "  0.7827005982398987),\n",
       " ([[555.2648405679842, 477.0452086006714],\n",
       "   [619.9802226094039, 526.5132376945834],\n",
       "   [586.7351594320158, 569.9547913993287],\n",
       "   [522.0197773905961, 520.4867623054166]],\n",
       "  'v9',\n",
       "  0.5539126992225647)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = '../test.jpeg'\n",
    "result = reader.readtext(image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "function takes exactly 4 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f19feccfb345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbottom_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspacer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mspacer\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: function takes exactly 4 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(image)\n",
    "spacer = 100\n",
    "for detection in result: \n",
    "    print('hi')\n",
    "    top_left = tuple(detection[0][0])\n",
    "    bottom_right = tuple(detection[0][2])\n",
    "    text = detection[1]\n",
    "    img = cv2.rectangle(img, top_left, bottom_right, (0,255,0), 3)\n",
    "    img = cv2.putText(img,text,(20,spacer), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
    "    spacer+=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
